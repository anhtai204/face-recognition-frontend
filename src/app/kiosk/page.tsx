"use client";

import { useEffect, useRef, useState } from "react";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import {
  Camera,
  Square,
  CheckCircle,
  XCircle,
  Loader2,
  AlertCircle,
  User,
} from "lucide-react";
import * as faceapi from "face-api.js";
import { useSession } from "next-auth/react";

interface AppEvent {
  id: string;
  title: string; // ƒê·ªïi name -> title cho kh·ªõp v·ªõi DB
  event_type: string;
  department: string | null;
}

interface DetectionResult {
  id: string;
  employeeName: string;
  accuracy: number;
  croppedFaceImage: string;
  timestamp: Date;
  eventName: string;
  isRecognized: boolean;
  message?: string;
}

export default function AdminCameraPage() {
  const { data: session } = useSession(); // L·∫•y token ƒë·ªÉ g·ªçi API
  const videoRef = useRef<HTMLVideoElement>(null);
  const overlayCanvasRef = useRef<HTMLCanvasElement>(null);
  const croppedCanvasRef = useRef<HTMLCanvasElement>(null);

  // State
  const [isStreaming, setIsStreaming] = useState(false);
  const [isAiReady, setIsAiReady] = useState(false);
  const [isRecognizing, setIsRecognizing] = useState(false);

  // Data State
  const [events, setEvents] = useState<AppEvent[]>([]);
  const [selectedEventId, setSelectedEventId] = useState<string>("");

  // Detection State
  const [detections, setDetections] = useState<DetectionResult[]>([]);
  const [error, setError] = useState<string>("");
  const [currentDetection, setCurrentDetection] =
    useState<faceapi.WithFaceLandmarks<{
      detection: faceapi.FaceDetection;
    }> | null>(null);
  const [recognizedName, setRecognizedName] = useState<string | null>(null);

  const RECOGNITION_INTERVAL = 2000; // 2 seconds

  // L∆∞u tr·∫°ng th√°i ƒëang b·∫≠n t√≠nh to√°n
  const isDetectingRef = useRef(false);
  // L∆∞u k·∫øt qu·∫£ detection cu·ªëi c√πng ƒë·ªÉ v·∫Ω li√™n t·ª•c (tr√°nh nh·∫•p nh√°y)
  const lastDetectionRef = useRef<any>(null);

  // 1. Load AI Models
  useEffect(() => {
    const loadModels = async () => {
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
          faceapi.nets.faceLandmark68TinyNet.loadFromUri("/models"),
        ]);
        setIsAiReady(true);
        console.log("AI models loaded successfully");
      } catch (err) {
        console.error("Failed to load AI models:", err);
        setError("Failed to load AI models. Check /public/models folder.");
      }
    };
    loadModels();
  }, []);

  // 2. Fetch Events t·ª´ API (Thay th·∫ø Mock Data)
  useEffect(() => {
    const fetchEvents = async () => {
      try {
        // Thay URL n√†y b·∫±ng endpoint th·ª±c t·∫ø c·ªßa b·∫°n
        const res = await fetch(
          `${process.env.NEXT_PUBLIC_BACKEND_URL}/api/v1/events/`,
          {
            headers: {
              Authorization: `Bearer ${session?.user?.access_token}`,
            },
          }
        );
        if (res.ok) {
          const data = await res.json();
          setEvents(data.data || []); // Gi·∫£ s·ª≠ API tr·∫£ v·ªÅ { data: [...] }
        }
      } catch (err) {
        console.error("Error fetching events:", err);
      }
    };
    if (session?.user?.access_token) {
      fetchEvents();
    }
  }, [session]);

  // 3. Start Camera (S·ª≠a l·ªói kh√¥ng ch·∫°y)
  const startCamera = async () => {
    console.log("--------------------------------------------------");
    console.log("[Camera Debug] 1. B·∫Øt ƒë·∫ßu h√†m startCamera");
    setError("");

    // Ki·ªÉm tra xem tr√¨nh duy·ªát c√≥ h·ªó tr·ª£ mediaDevices kh√¥ng
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      console.error(
        "[Camera Debug] L·ªói: Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ getUserMedia"
      );
      setError("Tr√¨nh duy·ªát c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ truy c·∫≠p Camera.");
      return;
    }

    try {
      console.log("[Camera Debug] 2. ƒêang y√™u c·∫ßu quy·ªÅn truy c·∫≠p Camera...");

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
        audio: false, // T·∫Øt ti·∫øng ƒë·ªÉ tr√°nh h√∫
      });

      console.log("[Camera Debug] 3. ƒê√£ nh·∫≠n ƒë∆∞·ª£c Stream:", stream.id);
      console.log("[Camera Debug]    - Active:", stream.active);
      console.log(
        "[Camera Debug]    - Tracks:",
        stream.getVideoTracks().length
      );

      if (videoRef.current) {
        console.log(
          "[Camera Debug] 4. T√¨m th·∫•y th·∫ª <video>, ƒëang g√°n stream..."
        );

        videoRef.current.srcObject = stream;

        console.log("[Camera Debug] 5. ƒêang g·ªçi l·ªánh .play()...");

        await videoRef.current.play();

        console.log("[Camera Debug] 6. Video ƒëang ch·∫°y (Playing)!");
        setIsStreaming(true);
      } else {
        console.error(
          "[Camera Debug] L·ªói: videoRef.current l√† null (Kh√¥ng t√¨m th·∫•y th·∫ª video trong DOM)"
        );
        setError("L·ªói giao di·ªán: Kh√¥ng t√¨m th·∫•y khung h√¨nh video.");
      }
    } catch (err: any) {
      console.error("[Camera Debug] --- X·∫¢Y RA L·ªñI ---");
      console.error("T√™n l·ªói:", err.name);
      console.error("Chi ti·∫øt:", err.message);
      console.error("To√†n b·ªô l·ªói:", err);

      if (
        err.name === "NotAllowedError" ||
        err.name === "PermissionDeniedError"
      ) {
        setError(
          "B·∫°n ƒë√£ CH·∫∂N quy·ªÅn camera. Vui l√≤ng b·∫•m v√†o bi·ªÉu t∆∞·ª£ng ·ªï kh√≥a tr√™n thanh ƒë·ªãa ch·ªâ ƒë·ªÉ m·ªü l·∫°i."
        );
      } else if (err.name === "NotFoundError") {
        setError("Kh√¥ng t√¨m th·∫•y thi·∫øt b·ªã Camera n√†o ƒë∆∞·ª£c k·∫øt n·ªëi.");
      } else if (err.name === "NotReadableError") {
        setError(
          "Camera ƒëang b·ªã ·ª©ng d·ª•ng kh√°c (Zoom/Meet/Teams) chi·∫øm d·ª•ng. H√£y t·∫Øt ch√∫ng ƒëi."
        );
      } else {
        setError(`L·ªói kh√¥ng x√°c ƒë·ªãnh: ${err.message}`);
      }
    }
  };

  const stopCamera = () => {
    if (videoRef.current?.srcObject) {
      const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
      tracks.forEach((track) => track.stop());
      setIsStreaming(false);
      setRecognizedName(null);
    }
  };

  // Helper: Crop ·∫£nh tr·∫£ v·ªÅ Blob ƒë·ªÉ g·ª≠i API
  const getCroppedImageBlob = async (
    detection: faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>
  ): Promise<Blob | null> => {
    if (!videoRef.current || !croppedCanvasRef.current) return null;

    const video = videoRef.current;
    const canvas = croppedCanvasRef.current;
    const { box } = detection.detection;

    canvas.width = box.width;
    canvas.height = box.height;

    const ctx = canvas.getContext("2d");
    if (!ctx) return null;

    ctx.drawImage(
      video,
      box.x,
      box.y,
      box.width,
      box.height,
      0,
      0,
      box.width,
      box.height
    );

    return new Promise((resolve) => {
      canvas.toBlob(
        (blob) => {
          resolve(blob);
        },
        "image/jpeg",
        0.9
      );
    });
  };

  // Helper: Crop ·∫£nh tr·∫£ v·ªÅ Base64 ƒë·ªÉ hi·ªÉn th·ªã UI
  const getCroppedImageBase64 = () => {
    return croppedCanvasRef.current?.toDataURL("image/jpeg") || "";
  };

  // 4. V√≤ng l·∫∑p V·∫Ω (60fps)
  const drawDetectionBox = async () => {
    // 1. Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng (T·∫Øt stream th√¨ d·ª´ng h·∫≥n)
    if (!isStreaming || !videoRef.current) return;

    // 2. Log Debug (Ch·ªâ hi·ªán 1 l·∫ßn ƒë·ªÉ check, tr√°nh spam console)
    // console.log("Loop is running...");

    // 3. Ki·ªÉm tra tr·∫°ng th√°i video
    if (
      !isAiReady ||
      videoRef.current.paused ||
      videoRef.current.ended ||
      videoRef.current.videoWidth === 0
    ) {
      // QUAN TR·ªåNG: V·∫´n g·ªçi l·∫°i frame ti·∫øp theo ƒë·ªÉ ch·ªù video s·∫µn s√†ng
      requestAnimationFrame(drawDetectionBox);
      return;
    }

    try {
      // --- A. PH√ÅT HI·ªÜN ---
      // D√πng TinyFaceDetectorOptions ƒë·ªÉ nhanh h∆°n
      const options = new faceapi.TinyFaceDetectorOptions({
        scoreThreshold: 0.5,
        inputSize: 224
      });

      const detection = await faceapi
        .detectSingleFace(videoRef.current, options)
        .withFaceLandmarks(true);

      setCurrentDetection(detection || null);

      // --- B. V·∫º ---
      const canvas = overlayCanvasRef.current;
      if (canvas) {
        // Kh·ªõp k√≠ch th∆∞·ªõc canvas v·ªõi video
        const dims = faceapi.matchDimensions(canvas, videoRef.current, true);

        const ctx = canvas.getContext("2d");
        if (ctx) {
          // X√≥a khung c≈©
          ctx.clearRect(0, 0, canvas.width, canvas.height);

          if (detection) {
            // console.log("üî• ƒê√É T√åM TH·∫§Y M·∫∂T!"); // Log n√†y s·∫Ω hi·ªán khi th·∫•y m·∫∑t

            const resizedDetection = faceapi.resizeResults(detection, dims);
            const { box } = resizedDetection.detection;

            // V·∫Ω khung
            const label = recognizedName || "Scanning...";
            const boxColor = recognizedName ? "#00FF00" : "#00BFFF"; // Xanh l√° ho·∫∑c Xanh d∆∞∆°ng

            const drawBox = new faceapi.draw.DrawBox(box, {
              label: label,
              boxColor: boxColor,
              lineWidth: 2,
            });
            drawBox.draw(canvas);
          }
        }
      }
    } catch (err) {
      console.error("L·ªói trong v√≤ng l·∫∑p AI:", err);
    }

    requestRef.current = requestAnimationFrame(drawDetectionBox);
    // 4. QUAN TR·ªåNG: G·ªçi l·∫°i ch√≠nh n√≥ ƒë·ªÉ t·∫°o v√≤ng l·∫∑p v√¥ t·∫≠n
    requestAnimationFrame(drawDetectionBox);
  };

  // 5. Logic Nh·∫≠n di·ªán (G·ªçi API th·ª±c t·∫ø)
  const performRecognition = async () => {
    if (!currentDetection || !selectedEventId || !session?.user?.access_token)
      return;

    setIsRecognizing(true);

    try {
      // A. L·∫•y ·∫£nh crop d·∫°ng Blob
      const imageBlob = await getCroppedImageBlob(currentDetection);
      if (!imageBlob) throw new Error("Failed to capture face image");

      // B. G·ª≠i l√™n Backend
      const formData = new FormData();
      formData.append("image_file", imageBlob, "capture.jpg");
      // N·∫øu API nh·∫≠n di·ªán c·∫ßn event_id ƒë·ªÉ ƒëi·ªÉm danh lu√¥n, g·ª≠i th√™m:
      // formData.append("event_id", selectedEventId)

      // G·ªçi endpoint nh·∫≠n di·ªán (S·ª≠ d·ª•ng endpoint nh·∫≠n di·ªán qua ·∫£nh crop)
      const res = await fetch(
        `${process.env.NEXT_PUBLIC_BACKEND_URL}/api/v1/face-recognition/recognize-crop`,
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${session.user.access_token}`,
          },
          body: formData,
        }
      );

      const data = await res.json();

      // C. X·ª≠ l√Ω k·∫øt qu·∫£
      const selectedEventObj = events.find((e) => e.id === selectedEventId);
      const eventName = selectedEventObj?.title || "Unknown Event";

      if (res.ok && data.is_recognized) {
        // --- TH√ÄNH C√îNG: ƒê√£ nh·∫≠n di·ªán ---
        const newDetection: DetectionResult = {
          id: crypto.randomUUID(),
          employeeName:
            data.message.replace("Khu√¥n m·∫∑t tr√πng kh·ªõp v·ªõi user ", "") ||
            "Unknown", // L·∫•y t√™n t·ª´ message ho·∫∑c response
          accuracy: Math.round((data.confidence || 0) * 100),
          croppedFaceImage: getCroppedImageBase64(), // Hi·ªÉn th·ªã ·∫£nh v·ª´a ch·ª•p
          timestamp: new Date(),
          eventName: eventName,
          isRecognized: true,
        };

        setRecognizedName(newDetection.employeeName); // C·∫≠p nh·∫≠t t√™n l√™n khung h√¨nh
        setDetections((prev) => [newDetection, ...prev].slice(0, 10)); // L∆∞u log

        // Reset t√™n sau 3 gi√¢y ƒë·ªÉ qu√©t ti·∫øp
        setTimeout(() => setRecognizedName(null), 3000);
      } else {
        // --- TH·∫§T B·∫†I: Kh√¥ng nh·∫≠n ra ---
        setRecognizedName("Unknown");
        // T√πy ch·ªçn: C√≥ l∆∞u log ng∆∞·ªùi l·∫° kh√¥ng? N·∫øu c√≥:
        /*
            setDetections(prev => [{
                id: crypto.randomUUID(),
                employeeName: "Unknown",
                accuracy: 0,
                croppedFaceImage: getCroppedImageBase64(),
                timestamp: new Date(),
                eventName: eventName,
                isRecognized: false
            }, ...prev].slice(0, 10))
            */
        setTimeout(() => setRecognizedName(null), 1000);
      }
    } catch (err) {
      console.error("Recognition error:", err);
      setRecognizedName("Error");
    } finally {
      setIsRecognizing(false);
    }
  };

  // K√≠ch ho·∫°t v√≤ng l·∫∑p v·∫Ω khi play video
  // useEffect(() => {
  //   if (isStreaming && isAiReady && videoRef.current) {
  //     // G·ª° b·ªè listener c≈© ƒë·ªÉ tr√°nh memory leak
  //     videoRef.current.removeEventListener("play", drawDetectionBox);
  //     videoRef.current.addEventListener("play", drawDetectionBox);
  //   }
  // }, [isStreaming, isAiReady]);

  const requestRef = useRef<number>(0);
  // --- S·ª¨A L·∫†I USEEFFECT K√çCH HO·∫†T ---
  // K√≠ch ho·∫°t v√≤ng l·∫∑p v·∫Ω
  useEffect(() => {
    const startLoop = () => {
      if (
        isStreaming &&
        isAiReady &&
        videoRef.current &&
        !videoRef.current.paused
      ) {
        drawDetectionBox();
      }
    };

    // K√≠ch ho·∫°t ngay
    startLoop();

    const videoEl = videoRef.current;
    if (videoEl) {
      videoEl.addEventListener("play", startLoop);
    }

    return () => {
      if (videoEl) {
        videoEl.removeEventListener("play", startLoop);
      }
      // S·ª¨A L·ªñI ·ªû ƒê√ÇY: H·ªßy frame t·ª´ ref
      if (requestRef.current) {
        cancelAnimationFrame(requestRef.current);
      }
    };
  }, [isStreaming, isAiReady]);

  // V√≤ng l·∫∑p g·ªçi API nh·∫≠n di·ªán (M·ªói 2 gi√¢y)
  useEffect(() => {
    if (!isStreaming || !isAiReady || !selectedEventId) return;

    const interval = setInterval(() => {
      // Ch·ªâ g·ªçi API n·∫øu ƒëang kh√¥ng b·∫≠n v√† c√≥ ph√°t hi·ªán khu√¥n m·∫∑t
      if (!isRecognizing && currentDetection) {
        performRecognition();
      }
    }, RECOGNITION_INTERVAL);

    return () => clearInterval(interval);
  }, [
    isStreaming,
    isAiReady,
    selectedEventId,
    currentDetection,
    isRecognizing,
  ]);

  return (
    <main className="flex-1 bg-background p-6 overflow-auto">
      <div className="max-w-6xl mx-auto">
        <div className="mb-6">
          <h1 className="text-3xl font-bold text-foreground mb-2">
            Camera Attendance
          </h1>
          <p className="text-foreground/60">
            Real-time facial recognition system
          </p>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* C·ªòT TR√ÅI: CAMERA */}
          <div className="lg:col-span-2">
            <Card className="overflow-hidden">
              <div className="bg-black relative aspect-video">
                {/* 1. LU√îN RENDER VIDEO (S·ª≠a class ƒë·ªÉ ·∫©n/hi·ªán) */}
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  // N·∫øu ƒëang stream th√¨ hi·ªán, kh√¥ng th√¨ ·∫©n (hidden)
                  className={`w-full h-full object-cover ${
                    isStreaming ? "block" : "hidden"
                  }`}
                />

                {/* 2. HI·ªÇN TH·ªä PLACEHOLDER KHI KH√îNG STREAM */}
                {!isStreaming && (
                  <div className="w-full h-full flex items-center justify-center absolute top-0 left-0">
                    <div className="text-center">
                      <Camera className="h-12 w-12 text-foreground/30 mx-auto mb-2" />
                      <p className="text-foreground/60">
                        Camera feed will appear here
                      </p>
                    </div>
                  </div>
                )}

                <canvas
                  ref={overlayCanvasRef}
                  className="absolute top-0 left-0 w-full h-full"
                />
                <canvas ref={croppedCanvasRef} className="hidden" />

                {/* Canvas ·∫©n ƒë·ªÉ crop ·∫£nh */}
                <canvas ref={croppedCanvasRef} className="hidden" />

                {!isAiReady && isStreaming && (
                  <div className="absolute top-0 left-0 w-full h-full flex items-center justify-center bg-black/50">
                    <Loader2 className="h-8 w-8 text-white animate-spin" />
                    <p className="text-white ml-2">Loading AI models...</p>
                  </div>
                )}
              </div>

              <div className="p-4 border-t border-border space-y-4">
                {/* Dropdown ch·ªçn s·ª± ki·ªán */}
                <div>
                  <label className="block text-sm font-medium text-foreground mb-2">
                    Select Event for Attendance
                  </label>
                  <select
                    value={selectedEventId}
                    onChange={(e) => setSelectedEventId(e.target.value)}
                    className="w-full px-3 py-2 bg-background border border-border rounded-md text-foreground"
                    disabled={events.length === 0}
                  >
                    <option value="">-- Choose an event --</option>
                    {events.map((event) => (
                      <option key={event.id} value={event.id}>
                        {event.title} ({event.event_type}){" "}
                        {event.department
                          ? `- ${event.department}`
                          : "- All Company"}
                      </option>
                    ))}
                  </select>
                  {events.length === 0 && (
                    <p className="text-xs text-red-500 mt-1">
                      No events found. Please create an event first.
                    </p>
                  )}
                </div>

                {/* N√∫t ƒëi·ªÅu khi·ªÉn */}
                <div className="flex gap-2">
                  {!isStreaming ? (
                    <Button onClick={startCamera} className="flex-1 gap-2">
                      <Camera className="h-4 w-4" />
                      Start Camera
                    </Button>
                  ) : (
                    <Button
                      onClick={stopCamera}
                      variant="destructive"
                      className="flex-1 gap-2"
                    >
                      <Square className="h-4 w-4" />
                      Stop Camera
                    </Button>
                  )}
                </div>

                {/* C·∫£nh b√°o */}
                {!selectedEventId && isStreaming && (
                  <div className="p-3 bg-amber-500/10 border border-amber-500/30 rounded-md text-amber-600 text-sm flex gap-2">
                    <AlertCircle className="h-4 w-4 flex-shrink-0 mt-0.5" />
                    <span>
                      Please select an event to start processing attendance.
                    </span>
                  </div>
                )}

                {error && (
                  <div className="p-3 bg-destructive/10 border border-destructive/30 rounded-md text-destructive text-sm">
                    {error}
                  </div>
                )}
              </div>
            </Card>
          </div>

          {/* C·ªòT PH·∫¢I: K·∫æT QU·∫¢ NH·∫¨N DI·ªÜN */}
          <div>
            <Card className="p-4 h-full flex flex-col">
              <h2 className="font-bold text-foreground mb-4">
                Recent Detections
              </h2>
              <div className="space-y-3 flex-1 overflow-y-auto max-h-[600px]">
                {detections.length === 0 ? (
                  <p className="text-foreground/60 text-sm text-center py-8">
                    {isStreaming && selectedEventId
                      ? "Scanning for registered faces..."
                      : "Waiting to start..."}
                  </p>
                ) : (
                  detections.map((detection) => (
                    <div
                      key={detection.id}
                      className={`p-3 border rounded-lg overflow-hidden ${
                        detection.isRecognized
                          ? "bg-green-500/10 border-green-500/30"
                          : "bg-red-500/10 border-red-500/30"
                      }`}
                    >
                      {detection.croppedFaceImage && (
                        <img
                          src={detection.croppedFaceImage}
                          alt="Face"
                          className="w-full h-24 object-contain bg-black/20 rounded mb-2"
                        />
                      )}

                      <div className="flex items-start gap-2">
                        {detection.isRecognized ? (
                          <CheckCircle className="h-4 w-4 text-green-500 mt-0.5 flex-shrink-0" />
                        ) : (
                          <User className="h-4 w-4 text-red-500 mt-0.5 flex-shrink-0" />
                        )}

                        <div className="flex-1 min-w-0">
                          <p className="font-bold text-foreground text-sm truncate">
                            {detection.employeeName}
                          </p>
                          <p className="text-xs text-foreground/60 mt-1">
                            Event: {detection.eventName}
                          </p>
                          <div className="flex justify-between items-center mt-2">
                            <span className="text-xs text-foreground/60">
                              {detection.timestamp.toLocaleTimeString()}
                            </span>
                            {detection.isRecognized && (
                              <span className="text-xs font-semibold text-green-600 bg-green-500/20 px-2 py-0.5 rounded">
                                {detection.accuracy}%
                              </span>
                            )}
                          </div>
                        </div>
                      </div>
                    </div>
                  ))
                )}
              </div>
            </Card>
          </div>
        </div>
      </div>
    </main>
  );
}
